{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,sys,datetime\n",
    "from itertools import repeat\n",
    "import shutil\n",
    "import sqlite3\n",
    "from DBConnector import Save_User,Update,connect_db,checkuser\n",
    "#import configparser\n",
    "from configparser import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This function will create an ID to identify tables\n",
    "def UniqueID (TableName):\n",
    "    mybytes = TableName.encode('utf-8')\n",
    "    ID = int.from_bytes(mybytes, 'little')\n",
    "    return ID\n",
    "    \n",
    "\n",
    "#We must check if the functions have appropriate format and they are correct   \n",
    "def Check_Parameters (Path,DestinationPath,DestinationPathToRename): \n",
    "    if (len(Path)>0 and os.path.isdir(Path)== True): \n",
    "            if(len(DestinationPath)>0):\n",
    "                print(os.path.isdir(DestinationPath))\n",
    "                return print(\"Everything Ok\")\n",
    "            else: \n",
    "                return print(\"Error: Variable empty\")\n",
    "    else: \n",
    "            return print(\"Error: Variable empty or it does not exist the origin path\")   \n",
    "    \n",
    "    return 1\n",
    "\n",
    "def checkcredentials ():\n",
    "    parser = ConfigParser()\n",
    "    parser.read('Variables.ini')\n",
    "    #Access \n",
    "    user = parser.get('Access_User', 'user')\n",
    "    password = parser.get('Access_User', 'password')\n",
    "    #Save_User(user,password)\n",
    "    check = checkuser(user)\n",
    "\n",
    "    if user == check[1] and password == check[2]:\n",
    "        print (\"Log in correctly\")\n",
    "    else: \n",
    "        print (\"Incorrect Password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " #We create a function that will be use for register table operations\n",
    "def Update (FileID,File,UploadDate,ModificationDate,Origin,Destiny,OperationType): \n",
    "    FileIDstr = str(FileID)\n",
    "    db = connect_db()    \n",
    "    #print(TableID,Table_Name,UploadDate,ModificationDate,Origin,Destiny,OperationType)\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(\"INSERT INTO ControlDataLake(FileID,File,UploadDate,ModificationDate,Origin,Destiny,OperationType) VALUES(?,?,?,?,?,?,?)\",\n",
    "                   (FileIDstr,File,UploadDate,ModificationDate,Origin,Destiny,OperationType))\n",
    "    db.commit()\n",
    "    \n",
    "\n",
    "#This Function will insert MetaData information to a database in order to control which type files and data goes to Datalake\n",
    "def InsertMetadata(DataGovernTable):\n",
    "\n",
    "    db = connect_db()    \n",
    "    cursor = db.cursor()\n",
    "\n",
    "    for i in range(len(DataGovernTable)):\n",
    "        #For every file we will create a row with its metadata\n",
    "        cursor.execute(\"INSERT INTO MetaData(FileID,TableName,Comment,CreationDate,ModificationDate,FileSize,FileType,StructuredData,Load,DateLoad) VALUES(?,?,?,?,?,?,?,?,?,?)\",\n",
    "        (str(DataGovernTable.iloc[i][0]),DataGovernTable.iloc[i][1],DataGovernTable.iloc[i][2],str(DataGovernTable.iloc[i][3]),str(DataGovernTable.iloc[i][4]),\n",
    "         DataGovernTable.iloc[i][5],DataGovernTable.iloc[i][6],DataGovernTable.iloc[i][7],DataGovernTable.iloc[i][8],DataGovernTable.iloc[i][9]))\n",
    "        \n",
    "    db.commit()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "#This Function will insert data table information in case the file would be a csv or excel or any kind of table\n",
    "def  InsertTablesData(TableFields):\n",
    "    db = connect_db()    \n",
    "    cursor = db.cursor()\n",
    "    for i in range(len(TableFields)):\n",
    "        cursor.execute(\"INSERT INTO TableControl(FileID,ColumnNames,DataTypes) VALUES(?,?,?)\",(str(TableFields.iloc[i][0]),str(TableFields.iloc[i][1]),str(TableFields.iloc[i][2])))\n",
    "    db.commit()\n",
    "\n",
    "    \n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ExtractMetadata (Path): #Function to extract the metadata in order to include in the governed table\n",
    "    metadata = dict()\n",
    "    arr = os.listdir(Path)\n",
    "    #Extracting all the metadata from files\n",
    "    for Files in arr:\n",
    "        FilePath = Path + '/' + Files\n",
    "        metadata.update({Files:os.stat(FilePath)})\n",
    "    return metadata\n",
    "\n",
    "def ExtractFilenames (Path): #The function will extract all the names from the path origin \n",
    "    arr = os.listdir(Path)\n",
    "    FileNames = []\n",
    "    for Files in arr:\n",
    "        FilePath = Files\n",
    "        FileNames.append(FilePath)\n",
    "    return FileNames\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Governed Table (Metadata Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def GovernedTable (Path): #This function will create a table to index and filter fields and information about data files\n",
    "    FileNames = ExtractFilenames(Path)\n",
    "    metadata = ExtractMetadata(Path)\n",
    "    DataGovern = pd.DataFrame ()\n",
    "    TableFields = pd.DataFrame ()\n",
    "    \n",
    "    \n",
    "    for names in FileNames:  #It will explore diferents files which are load\n",
    "        listacolumnas = dict()\n",
    "        \n",
    "        Extension = names[len(names)-3 : len(names)] #Getting the extension and the file type\n",
    "        if Extension == 'csv': #file is a csv\n",
    "            df= pd.read_csv(Path + '/' + names)        \n",
    "            columns = list(df.columns)\n",
    "            types   = list(df.dtypes)\n",
    "            IDTables  =list (repeat(UniqueID(names),len(types))) #We need to repeat the id as \n",
    "            TableFieldsnew = pd.DataFrame ({'TableId':IDTables,'Column Names':columns,'Data Type':types }) \n",
    "            TableFields = pd.concat([TableFields, TableFieldsnew])\n",
    "\n",
    "        \n",
    "        if Extension == 'csv' or Extension == 'xlsx':   \n",
    "            StructureData = 'Yes'\n",
    "        else: \n",
    "            StructureData = 'No'\n",
    "        #Metadata is save in a dataframe and it will be load to a table into the database \n",
    "        DataGovernDict = {'TableId':UniqueID(names),\n",
    "                'Table Name': names,\n",
    "                'Comment':'',  \n",
    "                'Creation Date': datetime.datetime.fromtimestamp(metadata[names][9]),\n",
    "                'Modification Date': datetime.datetime.fromtimestamp(metadata[names][8]),\n",
    "                'File Size': metadata[names][6], \n",
    "                'File Type': Extension,\n",
    "                'Structured Data':'Yes',\n",
    "                'Load': 'No',\n",
    "                'DateLoad': 'Never'}\n",
    "        # Data Governed table which inform about the metadata\n",
    "        DataGovernnew =  pd.DataFrame ([DataGovernDict]) # index=[0]) \n",
    "        DataGovern  = pd.concat([DataGovern, DataGovernnew], ignore_index=True)\n",
    "        \n",
    "    #Reset the index    \n",
    "    DataGovern.reset_index(drop= True, inplace = True) \n",
    "    InsertMetadata(DataGovern)\n",
    "    TableFields.reset_index(drop= True, inplace = True) \n",
    "    InsertTablesData(TableFields)\n",
    "    display(TableFields) \n",
    "    display (DataGovern)\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Files to DataLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def copycsvfile (TableName):\n",
    "    try:\n",
    "        shutil.copy(Path + '/' + TableName , DestinationPath + '/' + TableName)\n",
    "        print(\"File copied successfully.\")\n",
    "    except shutil.SameFileError:\n",
    "         print(\"Source and destination represents the same file.\")\n",
    "    # If there is any permission issue\n",
    "    except PermissionError:\n",
    "        print(\"Permission denied.\") \n",
    "    # For other errors\n",
    "    except:\n",
    "        print(\"Error occurred while copying file.\")\n",
    "    Update (UniqueID(TableName),str(TableName),str(datetime.datetime.now()),str(datetime.datetime.now()),Path + '/' + TableName,DestinationPath + '/' + TableName,Operations_Types[1] )\n",
    "    return print(\"Save it in the data lake\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Select Records  and insert them into governed table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only the columns we want to Load\n",
    "#Data should be available by time \n",
    "\n",
    "\n",
    "def Filter():\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create transaction create storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory():\n",
    "    print(\"Creating directory\")\n",
    "    directory = DestinationPath\n",
    "    try:\n",
    "        os.mkdir(directory) \n",
    "    except OSError as error: \n",
    "        print(error)  \n",
    "    print(\"The \" + directory + \" has been created \")\n",
    "    print(os.listdir(DestinationPath))\n",
    "        \n",
    "def delete_directory():\n",
    "    print(\"Deleting directory\")\n",
    "    directory = DestinationPath\n",
    "    try:\n",
    "        os.remove(DestinationPath)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s : %s\" % (directory, e.strerror))\n",
    "    print(\"The \" + directory + \" has been removed \")\n",
    "    print(os.listdir(DestinationPath))\n",
    "    \n",
    "def delete_file(File):\n",
    "    print(\"Deleting folder\")\n",
    "    directory = FolderPath\n",
    "    try:\n",
    "        os.remove(FolderPath)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s : %s\" % (directory, e.strerror))\n",
    "    Update (str(UniqueID (File)),File,str(datetime.datetime.now()),str(datetime.datetime.now()),Path + '/' + File,DestinationPath + '/' + File,Operations_Types[2] )\n",
    "    print(\"The \" + directory + \" has been removed \")\n",
    "    print(os.listdir(DestinationPath))\n",
    "        \n",
    "def rename_directory():\n",
    "    print(\"Renaming directory\")\n",
    "    directory = DestinationPath\n",
    "    try:\n",
    "        os.rename(DestinationPath,DestinationPathToRename)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(os.listdir(DestinationPath))\n",
    "    print(\"The \" + directory + \" has changed the name \")    \n",
    "    \n",
    "\n",
    "def list_directory_contents():\n",
    "    try:\n",
    "        print (\"Directory of the data lake is \" + DestinationPath )\n",
    "        print (\"There are  these files in the data lake: \") \n",
    "        print(os.listdir(DestinationPath))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write data into a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from governed table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrator, pipeline for manage it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log in correctly\n",
      "True\n",
      "Everything Ok\n",
      "1\n",
      "Deleting folder\n",
      "Error: D:\\GitHub\\Loka-Exercise\\DataLake\\Travel_Times - Manila.csv : The system cannot find the file specified\n",
      "The D:\\GitHub\\Loka-Exercise\\DataLake\\Travel_Times - Manila.csv has been removed \n",
      "['Travel_Times - Bogota.csv', 'Travel_Times - Boston.csv', 'Travel_Times - Johannesburg and Pretoria.csv', 'Travel_Times - Paris.csv', 'Travel_Times - Sydney.csv', 'Travel_Times - Washington DC.csv', 'Uber Movement - Travel Times Methodology.pdf']\n",
      "Directory of the data lake is D:\\GitHub\\Loka-Exercise\\DataLake\n",
      "There are  these files in the data lake: \n",
      "['Travel_Times - Bogota.csv', 'Travel_Times - Boston.csv', 'Travel_Times - Johannesburg and Pretoria.csv', 'Travel_Times - Paris.csv', 'Travel_Times - Sydney.csv', 'Travel_Times - Washington DC.csv', 'Uber Movement - Travel Times Methodology.pdf']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TableId</th>\n",
       "      <th>Column Names</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7435272962400543406716812426730517708988829779...</td>\n",
       "      <td>Origin Movement ID</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7435272962400543406716812426730517708988829779...</td>\n",
       "      <td>Origin Display Name</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7435272962400543406716812426730517708988829779...</td>\n",
       "      <td>Origin Geometry</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7435272962400543406716812426730517708988829779...</td>\n",
       "      <td>Destination Movement ID</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7435272962400543406716812426730517708988829779...</td>\n",
       "      <td>Destination Display Name</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5357678806540477621519797727373264419328100576...</td>\n",
       "      <td>Destination Geometry</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5357678806540477621519797727373264419328100576...</td>\n",
       "      <td>Date Range</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5357678806540477621519797727373264419328100576...</td>\n",
       "      <td>Mean Travel Time (Seconds)</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5357678806540477621519797727373264419328100576...</td>\n",
       "      <td>Range - Lower Bound Travel Time (Seconds)</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5357678806540477621519797727373264419328100576...</td>\n",
       "      <td>Range - Upper Bound Travel Time (Seconds)</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TableId  \\\n",
       "0   7435272962400543406716812426730517708988829779...   \n",
       "1   7435272962400543406716812426730517708988829779...   \n",
       "2   7435272962400543406716812426730517708988829779...   \n",
       "3   7435272962400543406716812426730517708988829779...   \n",
       "4   7435272962400543406716812426730517708988829779...   \n",
       "..                                                ...   \n",
       "61  5357678806540477621519797727373264419328100576...   \n",
       "62  5357678806540477621519797727373264419328100576...   \n",
       "63  5357678806540477621519797727373264419328100576...   \n",
       "64  5357678806540477621519797727373264419328100576...   \n",
       "65  5357678806540477621519797727373264419328100576...   \n",
       "\n",
       "                                 Column Names Data Type  \n",
       "0                          Origin Movement ID     int64  \n",
       "1                         Origin Display Name    object  \n",
       "2                             Origin Geometry    object  \n",
       "3                     Destination Movement ID     int64  \n",
       "4                    Destination Display Name    object  \n",
       "..                                        ...       ...  \n",
       "61                       Destination Geometry    object  \n",
       "62                                 Date Range    object  \n",
       "63                 Mean Travel Time (Seconds)     int64  \n",
       "64  Range - Lower Bound Travel Time (Seconds)     int64  \n",
       "65  Range - Upper Bound Travel Time (Seconds)     int64  \n",
       "\n",
       "[66 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TableId</th>\n",
       "      <th>Table Name</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Creation Date</th>\n",
       "      <th>Modification Date</th>\n",
       "      <th>File Size</th>\n",
       "      <th>File Type</th>\n",
       "      <th>Structured Data</th>\n",
       "      <th>Load</th>\n",
       "      <th>DateLoad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7435272962400543406716812426730517708988829779...</td>\n",
       "      <td>Travel_Times - Bogota.csv</td>\n",
       "      <td></td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>1552942</td>\n",
       "      <td>csv</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7435272962590254295522022852463171754428838246...</td>\n",
       "      <td>Travel_Times - Boston.csv</td>\n",
       "      <td></td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>1011715</td>\n",
       "      <td>csv</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4244790472089714976782803972576951162195729396...</td>\n",
       "      <td>Travel_Times - Johannesburg and Pretoria.csv</td>\n",
       "      <td></td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>37538</td>\n",
       "      <td>csv</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7435272962400085355460801306665012786460329521...</td>\n",
       "      <td>Travel_Times - Manila.csv</td>\n",
       "      <td></td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>340226</td>\n",
       "      <td>csv</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2904403501040229053180181379232863863208799904...</td>\n",
       "      <td>Travel_Times - Paris.csv</td>\n",
       "      <td></td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>334879</td>\n",
       "      <td>csv</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7435272962750447225474039193363105564547899403...</td>\n",
       "      <td>Travel_Times - Sydney.csv</td>\n",
       "      <td></td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>605074</td>\n",
       "      <td>csv</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5357678806540477621519797727373264419328100576...</td>\n",
       "      <td>Travel_Times - Washington DC.csv</td>\n",
       "      <td></td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>4350085</td>\n",
       "      <td>csv</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3669323166161444168241861682847098757601682877...</td>\n",
       "      <td>Uber Movement - Travel Times Methodology.pdf</td>\n",
       "      <td></td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>2022-10-23 18:45:47</td>\n",
       "      <td>90366</td>\n",
       "      <td>pdf</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             TableId  \\\n",
       "0  7435272962400543406716812426730517708988829779...   \n",
       "1  7435272962590254295522022852463171754428838246...   \n",
       "2  4244790472089714976782803972576951162195729396...   \n",
       "3  7435272962400085355460801306665012786460329521...   \n",
       "4  2904403501040229053180181379232863863208799904...   \n",
       "5  7435272962750447225474039193363105564547899403...   \n",
       "6  5357678806540477621519797727373264419328100576...   \n",
       "7  3669323166161444168241861682847098757601682877...   \n",
       "\n",
       "                                     Table Name Comment       Creation Date  \\\n",
       "0                     Travel_Times - Bogota.csv         2022-10-23 18:45:47   \n",
       "1                     Travel_Times - Boston.csv         2022-10-23 18:45:47   \n",
       "2  Travel_Times - Johannesburg and Pretoria.csv         2022-10-23 18:45:47   \n",
       "3                     Travel_Times - Manila.csv         2022-10-23 18:45:47   \n",
       "4                      Travel_Times - Paris.csv         2022-10-23 18:45:47   \n",
       "5                     Travel_Times - Sydney.csv         2022-10-23 18:45:47   \n",
       "6              Travel_Times - Washington DC.csv         2022-10-23 18:45:47   \n",
       "7  Uber Movement - Travel Times Methodology.pdf         2022-10-23 18:45:47   \n",
       "\n",
       "    Modification Date  File Size File Type Structured Data Load DateLoad  \n",
       "0 2022-10-23 18:45:47    1552942       csv             Yes   No    Never  \n",
       "1 2022-10-23 18:45:47    1011715       csv             Yes   No    Never  \n",
       "2 2022-10-23 18:45:47      37538       csv             Yes   No    Never  \n",
       "3 2022-10-23 18:45:47     340226       csv             Yes   No    Never  \n",
       "4 2022-10-23 18:45:47     334879       csv             Yes   No    Never  \n",
       "5 2022-10-23 18:45:47     605074       csv             Yes   No    Never  \n",
       "6 2022-10-23 18:45:47    4350085       csv             Yes   No    Never  \n",
       "7 2022-10-23 18:45:47      90366       pdf             Yes   No    Never  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied successfully.\n",
      "Save it in the data lake\n"
     ]
    }
   ],
   "source": [
    "#Main \n",
    "\n",
    "checkcredentials ()\n",
    "parser = ConfigParser()\n",
    "parser.read('Variables.ini')\n",
    "\n",
    "\n",
    "#Variables\n",
    "#First we define variables in order to extract the files from origins \n",
    "\n",
    "# Source path\n",
    "Path = parser.get('Variables_config', 'OriginPath')\n",
    "#Destination Path\n",
    "global DestinationPath\n",
    "DestinationPath = parser.get('Variables_config', 'DestinationPath')\n",
    "#New name for DataLake\n",
    "DestinationPathToRename = parser.get('Variables_config', 'DestinationPathToRename')\n",
    "#Name of the Folder to delete\n",
    "global FolderPath\n",
    "FolderPath = parser.get('Variables_config', 'FolderPath')\n",
    "FileDel =  parser.get('Variables_config', 'FileDel')\n",
    "\n",
    "#Types of Operations\n",
    "global Operations_Types\n",
    "Operations_Types = {\n",
    "    1: \"File Saved\",\n",
    "    2: \"File Deleted\",\n",
    "    3: \"File Modificated\"\n",
    "}\n",
    "\n",
    "\n",
    "Check_Parameters (Path,DestinationPath,DestinationPathToRename)\n",
    "\n",
    "print(parser.get('Directory_Options', 'list_directory_contents'))        \n",
    "if parser.get('Directory_Options', 'Create_directory') == \"1\":\n",
    "    create_directory()\n",
    "if parser.get('Directory_Options', 'Delete_directory') == \"1\":\n",
    "    delete_directory()\n",
    "if parser.get('Directory_Options', 'Delete_file') == \"1\":\n",
    "    delete_file(FileDel)\n",
    "if parser.get('Directory_Options', 'Rename_directory') == \"1\":\n",
    "    rename_directory()\n",
    "if parser.get('Directory_Options', 'list_directory_contents') == \"1\":\n",
    "    list_directory_contents()\n",
    "    \n",
    "GovernedTable(Path)\n",
    "\n",
    "if parser.get('Variables_config', 'FilesLoad') == \"ALL\":\n",
    "    FileNames = ExtractFilenames(Path)\n",
    "    for Files in FileNames: #Loading all files in the origin\n",
    "        print (Files)\n",
    "        copycsvfile(Files)\n",
    "else: \n",
    "        FileLoad = parser.get('Variables_config', 'FilesLoad')\n",
    "        copycsvfile(FileLoad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute every Two Minutes \n",
    "# It would be unproductive to use airflow due to it is managed in a local way \n",
    "# with DAG (\n",
    "#         dag_id=\"firt_dag\",\n",
    "#         schedule_interval=\"@daily\",\n",
    "#         default_args={\n",
    "#             \"owner\": \"airflow\",\n",
    "#             \"retries\":1\n",
    "#             \"start_date\":datatime(2022,10,26) \n",
    "#         }\n",
    "#     ) as f:\n",
    "#     check_file = PythonOperator(\n",
    "#     task_id = \"Check_Parameters\"\n",
    "#         Check_Parameters ()\n",
    "#         pass\n",
    "\n",
    "    # cursor.execute(\"INSERT INTO ControlDataLake(FileID,File,UploadDate,ModificationDate,Origin,Destiny,OperationType) VALUES(?,?,?,?,?,?,?)\",(str(DataGovernTable.iloc[i][0]),DataGovernTable.iloc[i][1],str(datetime.datetime.now()),str(datetime.datetime.now()),Path,DestinationPath,Operations_Types[1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "713aa0a7fb6ac31a656cdd9131ae9b49ed44084d30532e76b110f7e001e0a95d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
